Next session plan (Scenic OWLv2)
1) Use absolute config path: PYTHONPATH=/home/nitin/scenic:/home/nitin/big_vision:$PYTHONPATH JAX_PLATFORM_NAME=cpu XLA_PYTHON_CLIENT_PREALLOCATE=false /home/nitin/gdinovenv/bin/python -m scenic.projects.owl_vit.main --config=/home/nitin/scenic/scenic/projects/owl_vit/configs/finetune.py --workdir=/mnt/e/idfc_genai/scenic_runs/owlv2_sigstamp --config.experiment_name=owlv2_sigstamp --config.model_name=owl_vit_b16 --config.dataset_configs.train_file_pattern="/mnt/e/idfc_genai/owlv2_tfrecords/train-*.tfrecord" --config.dataset_configs.validation_file_pattern="/mnt/e/idfc_genai/owlv2_tfrecords/train-*.tfrecord" --config.dataset_configs.class_names='["signature","stamp"]' --config.dataset_configs.decoder_kwarg_list='[{"name":"coco_sigstamp:0.0.1"}]' --config.init_from.checkpoint_path=/home/nitin/.cache/huggingface/hub/models--google--owlv2-base-patch16-ensemble/snapshots/cfd3195ba4ea9592eec887ded089f4c08eff231d --config.trainer_name=owlv2 --config.batch_size=1 --config.num_training_steps=20000 --config.log_loss_every_steps=100 --config.eval_every_steps=1000
2) If GPU is desired and cuInit errors persist, try: export LD_LIBRARY_PATH=/home/nitin/gdinovenv/lib/python3.10/site-packages/nvidia/cudnn/lib:$LD_LIBRARY_PATH and rerun without JAX_PLATFORM_NAME=cpu.
3) Ensure ott-jax patch is kept (sed replace PRNGKeyArray -> jax.Array already done). If errors reappear, rerun: find /home/nitin/gdinovenv/lib/python3.10/site-packages/ott -type f -name "*.py" -exec sed -i 's/jax.random.PRNGKeyArray/jax.Array/g' {} +
4) If main still fails due to missing big_vision, verify /home/nitin/big_vision exists; if not, clone google-research/big_vision into /home/nitin/big_vision.
5) After training, run stage_top15 for annotation queue: python3 stage_top15_owlv2.py --model-path owlv2_custom_out --processor-path owlv2_custom_out --device cuda:0 --image-size 640 --threshold 0.1 --topk 15.
6) TFRecords already generated at /mnt/e/idfc_genai/owlv2_tfrecords (49 examples; image id 47 skipped).
Updates after latest attempts:
- Config file finetune.py does not exist. Use /home/nitin/scenic/scenic/projects/owl_vit/configs/clip_b32_finetune.py as a base or create a new finetune config that uses the coco_sigstamp decoder and tfrecord file patterns.
- Current command failed because config path missing and cuInit(0) failed: CUDA_ERROR_OPERATING_SYSTEM. GPU may be blocked; consider JAX_PLATFORM_NAME=cpu to proceed slowly, or fix WSL GPU access.
- CLIP dependency installed via pip; ott-jax patched.
- Suggested next command (CPU fallback; replace config path with custom finetune config when created):
PYTHONPATH=/home/nitin/scenic:/home/nitin/big_vision:$PYTHONPATH JAX_PLATFORM_NAME=cpu XLA_PYTHON_CLIENT_PREALLOCATE=false /home/nitin/gdinovenv/bin/python -m scenic.projects.owl_vit.main --config=/home/nitin/scenic/scenic/projects/owl_vit/configs/<your_finetune_config>.py --workdir=/mnt/e/idfc_genai/scenic_runs/owlv2_sigstamp --config.experiment_name=owlv2_sigstamp --config.model_name=owl_vit_b16 --config.dataset_configs.train_file_pattern="/mnt/e/idfc_genai/owlv2_tfrecords/train-*.tfrecord" --config.dataset_configs.validation_file_pattern="/mnt/e/idfc_genai/owlv2_tfrecords/train-*.tfrecord" --config.dataset_configs.class_names='["signature","stamp"]' --config.dataset_configs.decoder_kwarg_list='[{"name":"coco_sigstamp:0.0.1"}]' --config.init_from.checkpoint_path=/home/nitin/.cache/huggingface/hub/models--google--owlv2-base-patch16-ensemble/snapshots/cfd3195ba4ea9592eec887ded089f4c08eff231d --config.trainer_name=owlv2 --config.batch_size=1 --config.num_training_steps=20000 --config.log_loss_every_steps=100 --config.eval_every_steps=1000
